# -*- coding: utf-8 -*-
"""DCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E2zjxLTDd4D4jDHdRcA6-0u-p-SwavEB

sharry

aiml b2
22070126104
"""

"""
DCGAN Implementation on CIFAR-10 Dataset
---------------------------------------
This script trains a Deep Convolutional GAN (DCGAN) on the CIFAR-10 dataset.
- Uses PyTorch for implementation
- Includes Generator and Discriminator networks
- Trains for 50 epochs
- Saves and displays generated images
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torchvision.utils as vutils
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import os

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Hyperparameters
lr = 0.0002  # Learning rate for optimizers
batch_size = 64  # Batch size for training
image_size = 32  # CIFAR-10 images are 32x32 pixels
z_dim = 100  # Latent vector dimension
num_epochs = 50  # Number of epochs for training
features_gen = 64  # Generator feature maps
features_disc = 64  # Discriminator feature maps
beta1 = 0.5  # Momentum term for Adam optimizer

# Data transformation pipeline
transform = transforms.Compose([
    transforms.Resize(image_size),
    transforms.ToTensor(),
    transforms.Normalize([0.5] * 3, [0.5] * 3)  # Normalize images to [-1,1] range
])

# Load CIFAR-10 dataset
dataset = datasets.CIFAR10(root="data", train=True, transform=transform, download=True)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)

class Discriminator(nn.Module):
    """
    Discriminator network for DCGAN.
    A convolutional neural network that classifies images as real or fake.
    """
    def __init__(self, channels_img, features_d):
        super(Discriminator, self).__init__()
        self.disc = nn.Sequential(
            nn.Conv2d(channels_img, features_d, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(features_d, features_d * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(features_d * 2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(features_d * 2, features_d * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(features_d * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(features_d * 4, 1, 4, 1, 0, bias=False)  # No Sigmoid (for BCEWithLogitsLoss)
        )

    def forward(self, x):
        return self.disc(x)

class Generator(nn.Module):
    """
    Generator network for DCGAN.
    Takes a latent vector and generates a synthetic image.
    """
    def __init__(self, z_dim, channels_img, features_g):
        super(Generator, self).__init__()
        self.gen = nn.Sequential(
            nn.ConvTranspose2d(z_dim, features_g * 4, 4, 1, 0, bias=False),
            nn.BatchNorm2d(features_g * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(features_g * 4, features_g * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(features_g * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(features_g * 2, features_g, 4, 2, 1, bias=False),
            nn.BatchNorm2d(features_g),
            nn.ReLU(True),
            nn.ConvTranspose2d(features_g, channels_img, 4, 2, 1, bias=False),
            nn.Tanh()  # Outputs values in range [-1,1]
        )

    def forward(self, x):
        return self.gen(x)

# Initialize models
gen = Generator(z_dim, 3, features_gen).to(device)
disc = Discriminator(3, features_disc).to(device)

# Loss and Optimizers
criterion = nn.BCEWithLogitsLoss()  # More stable loss function
optimizer_gen = optim.Adam(gen.parameters(), lr=lr, betas=(beta1, 0.999))
optimizer_disc = optim.Adam(disc.parameters(), lr=lr, betas=(beta1, 0.999))

# Noise for visualization
fixed_noise = torch.randn(64, z_dim, 1, 1, device=device)

# Training Loop
print("Starting Training...")
for epoch in range(num_epochs):
    for batch_idx, (real, _) in enumerate(tqdm(dataloader)):
        real = real.to(device)
        noise = torch.randn(batch_size, z_dim, 1, 1, device=device)
        fake = gen(noise)

        # Train Discriminator
        optimizer_disc.zero_grad()
        disc_real = disc(real).view(-1)
        lossD_real = criterion(disc_real, torch.ones_like(disc_real))

        disc_fake = disc(fake.detach()).view(-1)
        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))

        lossD = (lossD_real + lossD_fake) / 2
        lossD.backward()
        optimizer_disc.step()

        # Train Generator
        optimizer_gen.zero_grad()
        output = disc(fake).view(-1)
        lossG = criterion(output, torch.ones_like(output))
        lossG.backward()
        optimizer_gen.step()

    # Save generated images
    with torch.no_grad():
        fake_images = gen(fixed_noise).detach().cpu()
        vutils.save_image(fake_images, f"generated_epoch_{epoch}.png", normalize=True)

print("Training Complete!")

